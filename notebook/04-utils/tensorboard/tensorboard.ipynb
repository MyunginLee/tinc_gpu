{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from logger import Logger\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MNIST dataset \n",
    "dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                     train=True, \n",
    "                                     transform=transforms.ToTensor(),  \n",
    "                                     download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)\n",
    "\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet().to(device)\n",
    "\n",
    "logger = Logger('./logs') #Logger.__init__(self, log_dir): Create a summary writer logging to log_dir.\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.data.dataloader.DataLoader to torch.utils.data.dataloader._DataLoaderIter\n",
    "data_iter = iter(data_loader) \n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/50000], Loss: 2.2154, Acc: 0.41\n",
      "Step [200/50000], Loss: 2.1110, Acc: 0.65\n",
      "Step [300/50000], Loss: 2.0177, Acc: 0.76\n",
      "Step [400/50000], Loss: 1.8438, Acc: 0.79\n",
      "Step [500/50000], Loss: 1.6922, Acc: 0.82\n",
      "Step [600/50000], Loss: 1.5949, Acc: 0.77\n",
      "Step [700/50000], Loss: 1.5189, Acc: 0.75\n",
      "Step [800/50000], Loss: 1.4046, Acc: 0.80\n",
      "Step [900/50000], Loss: 1.2296, Acc: 0.87\n",
      "Step [1000/50000], Loss: 1.0934, Acc: 0.86\n",
      "Step [1100/50000], Loss: 1.0664, Acc: 0.88\n",
      "Step [1200/50000], Loss: 1.0420, Acc: 0.84\n",
      "Step [1300/50000], Loss: 0.9207, Acc: 0.86\n",
      "Step [1400/50000], Loss: 0.8425, Acc: 0.85\n",
      "Step [1500/50000], Loss: 0.8956, Acc: 0.78\n",
      "Step [1600/50000], Loss: 0.8901, Acc: 0.76\n",
      "Step [1700/50000], Loss: 0.7378, Acc: 0.87\n",
      "Step [1800/50000], Loss: 0.7390, Acc: 0.81\n",
      "Step [1900/50000], Loss: 0.6066, Acc: 0.88\n",
      "Step [2000/50000], Loss: 0.7477, Acc: 0.86\n",
      "Step [2100/50000], Loss: 0.5677, Acc: 0.90\n",
      "Step [2200/50000], Loss: 0.5867, Acc: 0.87\n",
      "Step [2300/50000], Loss: 0.5638, Acc: 0.90\n",
      "Step [2400/50000], Loss: 0.6072, Acc: 0.86\n",
      "Step [2500/50000], Loss: 0.7338, Acc: 0.83\n",
      "Step [2600/50000], Loss: 0.5360, Acc: 0.83\n",
      "Step [2700/50000], Loss: 0.5677, Acc: 0.84\n",
      "Step [2800/50000], Loss: 0.6237, Acc: 0.81\n",
      "Step [2900/50000], Loss: 0.5106, Acc: 0.89\n",
      "Step [3000/50000], Loss: 0.4562, Acc: 0.89\n",
      "Step [3100/50000], Loss: 0.4662, Acc: 0.91\n",
      "Step [3200/50000], Loss: 0.4327, Acc: 0.91\n",
      "Step [3300/50000], Loss: 0.4133, Acc: 0.92\n",
      "Step [3400/50000], Loss: 0.6505, Acc: 0.83\n",
      "Step [3500/50000], Loss: 0.5025, Acc: 0.87\n",
      "Step [3600/50000], Loss: 0.3746, Acc: 0.90\n",
      "Step [3700/50000], Loss: 0.4904, Acc: 0.87\n",
      "Step [3800/50000], Loss: 0.4629, Acc: 0.89\n",
      "Step [3900/50000], Loss: 0.3490, Acc: 0.90\n",
      "Step [4000/50000], Loss: 0.5066, Acc: 0.87\n",
      "Step [4100/50000], Loss: 0.4404, Acc: 0.89\n",
      "Step [4200/50000], Loss: 0.3980, Acc: 0.92\n",
      "Step [4300/50000], Loss: 0.3705, Acc: 0.93\n",
      "Step [4400/50000], Loss: 0.4678, Acc: 0.85\n",
      "Step [4500/50000], Loss: 0.3484, Acc: 0.91\n",
      "Step [4600/50000], Loss: 0.3343, Acc: 0.93\n",
      "Step [4700/50000], Loss: 0.4494, Acc: 0.90\n",
      "Step [4800/50000], Loss: 0.4701, Acc: 0.85\n",
      "Step [4900/50000], Loss: 0.4617, Acc: 0.85\n",
      "Step [5000/50000], Loss: 0.3598, Acc: 0.92\n",
      "Step [5100/50000], Loss: 0.4578, Acc: 0.86\n",
      "Step [5200/50000], Loss: 0.4103, Acc: 0.86\n",
      "Step [5300/50000], Loss: 0.4344, Acc: 0.87\n",
      "Step [5400/50000], Loss: 0.4629, Acc: 0.90\n",
      "Step [5500/50000], Loss: 0.3053, Acc: 0.93\n",
      "Step [5600/50000], Loss: 0.3683, Acc: 0.91\n",
      "Step [5700/50000], Loss: 0.4566, Acc: 0.85\n",
      "Step [5800/50000], Loss: 0.3361, Acc: 0.92\n",
      "Step [5900/50000], Loss: 0.3687, Acc: 0.90\n",
      "Step [6000/50000], Loss: 0.2770, Acc: 0.93\n",
      "Step [6100/50000], Loss: 0.3100, Acc: 0.92\n",
      "Step [6200/50000], Loss: 0.4238, Acc: 0.91\n",
      "Step [6300/50000], Loss: 0.2889, Acc: 0.93\n",
      "Step [6400/50000], Loss: 0.4389, Acc: 0.90\n",
      "Step [6500/50000], Loss: 0.3880, Acc: 0.87\n",
      "Step [6600/50000], Loss: 0.3064, Acc: 0.92\n",
      "Step [6700/50000], Loss: 0.2070, Acc: 0.95\n",
      "Step [6800/50000], Loss: 0.4844, Acc: 0.88\n",
      "Step [6900/50000], Loss: 0.2514, Acc: 0.94\n",
      "Step [7000/50000], Loss: 0.2626, Acc: 0.94\n",
      "Step [7100/50000], Loss: 0.2724, Acc: 0.94\n",
      "Step [7200/50000], Loss: 0.2945, Acc: 0.91\n",
      "Step [7300/50000], Loss: 0.3560, Acc: 0.89\n",
      "Step [7400/50000], Loss: 0.4297, Acc: 0.88\n",
      "Step [7500/50000], Loss: 0.3259, Acc: 0.93\n",
      "Step [7600/50000], Loss: 0.4291, Acc: 0.85\n",
      "Step [7700/50000], Loss: 0.3710, Acc: 0.88\n",
      "Step [7800/50000], Loss: 0.3937, Acc: 0.88\n",
      "Step [7900/50000], Loss: 0.4052, Acc: 0.91\n",
      "Step [8000/50000], Loss: 0.3904, Acc: 0.90\n",
      "Step [8100/50000], Loss: 0.2046, Acc: 0.96\n",
      "Step [8200/50000], Loss: 0.2717, Acc: 0.94\n",
      "Step [8300/50000], Loss: 0.3526, Acc: 0.90\n",
      "Step [8400/50000], Loss: 0.4916, Acc: 0.82\n",
      "Step [8500/50000], Loss: 0.3752, Acc: 0.88\n",
      "Step [8600/50000], Loss: 0.2699, Acc: 0.93\n",
      "Step [8700/50000], Loss: 0.2876, Acc: 0.91\n",
      "Step [8800/50000], Loss: 0.2824, Acc: 0.91\n",
      "Step [8900/50000], Loss: 0.3303, Acc: 0.93\n",
      "Step [9000/50000], Loss: 0.4498, Acc: 0.87\n",
      "Step [9100/50000], Loss: 0.2945, Acc: 0.95\n",
      "Step [9200/50000], Loss: 0.2730, Acc: 0.92\n",
      "Step [9300/50000], Loss: 0.2393, Acc: 0.93\n",
      "Step [9400/50000], Loss: 0.3722, Acc: 0.93\n",
      "Step [9500/50000], Loss: 0.2461, Acc: 0.91\n",
      "Step [9600/50000], Loss: 0.2797, Acc: 0.91\n",
      "Step [9700/50000], Loss: 0.4253, Acc: 0.92\n",
      "Step [9800/50000], Loss: 0.5084, Acc: 0.86\n",
      "Step [9900/50000], Loss: 0.2427, Acc: 0.92\n",
      "Step [10000/50000], Loss: 0.2384, Acc: 0.94\n",
      "Step [10100/50000], Loss: 0.3548, Acc: 0.91\n",
      "Step [10200/50000], Loss: 0.2957, Acc: 0.90\n",
      "Step [10300/50000], Loss: 0.3214, Acc: 0.91\n",
      "Step [10400/50000], Loss: 0.2895, Acc: 0.89\n",
      "Step [10500/50000], Loss: 0.1436, Acc: 0.98\n",
      "Step [10600/50000], Loss: 0.2589, Acc: 0.91\n",
      "Step [10700/50000], Loss: 0.3092, Acc: 0.92\n",
      "Step [10800/50000], Loss: 0.2264, Acc: 0.95\n",
      "Step [10900/50000], Loss: 0.3542, Acc: 0.87\n",
      "Step [11000/50000], Loss: 0.3337, Acc: 0.92\n",
      "Step [11100/50000], Loss: 0.3797, Acc: 0.89\n",
      "Step [11200/50000], Loss: 0.1821, Acc: 0.96\n",
      "Step [11300/50000], Loss: 0.3483, Acc: 0.92\n",
      "Step [11400/50000], Loss: 0.2487, Acc: 0.95\n",
      "Step [11500/50000], Loss: 0.3200, Acc: 0.92\n",
      "Step [11600/50000], Loss: 0.3090, Acc: 0.89\n",
      "Step [11700/50000], Loss: 0.2372, Acc: 0.93\n",
      "Step [11800/50000], Loss: 0.2739, Acc: 0.94\n",
      "Step [11900/50000], Loss: 0.1943, Acc: 0.95\n",
      "Step [12000/50000], Loss: 0.2180, Acc: 0.96\n",
      "Step [12100/50000], Loss: 0.3649, Acc: 0.87\n",
      "Step [12200/50000], Loss: 0.2392, Acc: 0.95\n",
      "Step [12300/50000], Loss: 0.2974, Acc: 0.92\n",
      "Step [12400/50000], Loss: 0.2684, Acc: 0.90\n",
      "Step [12500/50000], Loss: 0.2546, Acc: 0.93\n",
      "Step [12600/50000], Loss: 0.1771, Acc: 0.97\n",
      "Step [12700/50000], Loss: 0.2260, Acc: 0.91\n",
      "Step [12800/50000], Loss: 0.1922, Acc: 0.93\n",
      "Step [12900/50000], Loss: 0.3275, Acc: 0.93\n",
      "Step [13000/50000], Loss: 0.2992, Acc: 0.90\n",
      "Step [13100/50000], Loss: 0.3131, Acc: 0.90\n",
      "Step [13200/50000], Loss: 0.2517, Acc: 0.93\n",
      "Step [13300/50000], Loss: 0.3092, Acc: 0.87\n",
      "Step [13400/50000], Loss: 0.1834, Acc: 0.95\n",
      "Step [13500/50000], Loss: 0.3185, Acc: 0.92\n",
      "Step [13600/50000], Loss: 0.2465, Acc: 0.92\n",
      "Step [13700/50000], Loss: 0.3166, Acc: 0.92\n",
      "Step [13800/50000], Loss: 0.5410, Acc: 0.91\n",
      "Step [13900/50000], Loss: 0.3120, Acc: 0.90\n",
      "Step [14000/50000], Loss: 0.1630, Acc: 0.96\n",
      "Step [14100/50000], Loss: 0.2886, Acc: 0.92\n",
      "Step [14200/50000], Loss: 0.2427, Acc: 0.95\n",
      "Step [14300/50000], Loss: 0.2736, Acc: 0.93\n",
      "Step [14400/50000], Loss: 0.2319, Acc: 0.95\n",
      "Step [14500/50000], Loss: 0.2413, Acc: 0.93\n",
      "Step [14600/50000], Loss: 0.1461, Acc: 0.98\n",
      "Step [14700/50000], Loss: 0.3554, Acc: 0.95\n",
      "Step [14800/50000], Loss: 0.1950, Acc: 0.93\n",
      "Step [14900/50000], Loss: 0.2371, Acc: 0.88\n",
      "Step [15000/50000], Loss: 0.2581, Acc: 0.96\n",
      "Step [15100/50000], Loss: 0.2375, Acc: 0.94\n",
      "Step [15200/50000], Loss: 0.2762, Acc: 0.96\n",
      "Step [15300/50000], Loss: 0.2493, Acc: 0.95\n",
      "Step [15400/50000], Loss: 0.2758, Acc: 0.91\n",
      "Step [15500/50000], Loss: 0.3330, Acc: 0.90\n",
      "Step [15600/50000], Loss: 0.1790, Acc: 0.94\n",
      "Step [15700/50000], Loss: 0.1795, Acc: 0.96\n",
      "Step [15800/50000], Loss: 0.1920, Acc: 0.97\n",
      "Step [15900/50000], Loss: 0.2081, Acc: 0.96\n",
      "Step [16000/50000], Loss: 0.2365, Acc: 0.95\n",
      "Step [16100/50000], Loss: 0.3463, Acc: 0.93\n",
      "Step [16200/50000], Loss: 0.3383, Acc: 0.89\n",
      "Step [16300/50000], Loss: 0.2461, Acc: 0.92\n",
      "Step [16400/50000], Loss: 0.4500, Acc: 0.88\n",
      "Step [16500/50000], Loss: 0.1710, Acc: 0.96\n",
      "Step [16600/50000], Loss: 0.3180, Acc: 0.93\n",
      "Step [16700/50000], Loss: 0.2072, Acc: 0.92\n",
      "Step [16800/50000], Loss: 0.2364, Acc: 0.92\n",
      "Step [16900/50000], Loss: 0.1992, Acc: 0.93\n",
      "Step [17000/50000], Loss: 0.2204, Acc: 0.93\n",
      "Step [17100/50000], Loss: 0.3625, Acc: 0.91\n",
      "Step [17200/50000], Loss: 0.1631, Acc: 0.98\n",
      "Step [17300/50000], Loss: 0.2265, Acc: 0.92\n",
      "Step [17400/50000], Loss: 0.3620, Acc: 0.93\n",
      "Step [17500/50000], Loss: 0.1410, Acc: 0.98\n",
      "Step [17600/50000], Loss: 0.1408, Acc: 0.96\n",
      "Step [17700/50000], Loss: 0.1651, Acc: 0.96\n",
      "Step [17800/50000], Loss: 0.1576, Acc: 0.95\n",
      "Step [17900/50000], Loss: 0.2563, Acc: 0.93\n",
      "Step [18000/50000], Loss: 0.0972, Acc: 0.98\n",
      "Step [18100/50000], Loss: 0.1756, Acc: 0.94\n",
      "Step [18200/50000], Loss: 0.2718, Acc: 0.92\n",
      "Step [18300/50000], Loss: 0.1331, Acc: 0.98\n",
      "Step [18400/50000], Loss: 0.0999, Acc: 0.98\n",
      "Step [18500/50000], Loss: 0.1517, Acc: 0.97\n",
      "Step [18600/50000], Loss: 0.2912, Acc: 0.92\n",
      "Step [18700/50000], Loss: 0.4227, Acc: 0.89\n",
      "Step [18800/50000], Loss: 0.1183, Acc: 0.95\n",
      "Step [18900/50000], Loss: 0.1706, Acc: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [19000/50000], Loss: 0.2430, Acc: 0.96\n",
      "Step [19100/50000], Loss: 0.3173, Acc: 0.90\n",
      "Step [19200/50000], Loss: 0.2299, Acc: 0.91\n",
      "Step [19300/50000], Loss: 0.2688, Acc: 0.94\n",
      "Step [19400/50000], Loss: 0.2585, Acc: 0.92\n",
      "Step [19500/50000], Loss: 0.1499, Acc: 0.98\n",
      "Step [19600/50000], Loss: 0.1107, Acc: 0.97\n",
      "Step [19700/50000], Loss: 0.1931, Acc: 0.94\n",
      "Step [19800/50000], Loss: 0.1426, Acc: 0.95\n",
      "Step [19900/50000], Loss: 0.1790, Acc: 0.95\n",
      "Step [20000/50000], Loss: 0.2355, Acc: 0.93\n",
      "Step [20100/50000], Loss: 0.1467, Acc: 0.98\n",
      "Step [20200/50000], Loss: 0.2687, Acc: 0.92\n",
      "Step [20300/50000], Loss: 0.1625, Acc: 0.95\n",
      "Step [20400/50000], Loss: 0.3327, Acc: 0.90\n",
      "Step [20500/50000], Loss: 0.1575, Acc: 0.95\n",
      "Step [20600/50000], Loss: 0.1717, Acc: 0.95\n",
      "Step [20700/50000], Loss: 0.2281, Acc: 0.92\n",
      "Step [20800/50000], Loss: 0.2486, Acc: 0.94\n",
      "Step [20900/50000], Loss: 0.1954, Acc: 0.94\n",
      "Step [21000/50000], Loss: 0.1758, Acc: 0.96\n",
      "Step [21100/50000], Loss: 0.1686, Acc: 0.97\n",
      "Step [21200/50000], Loss: 0.1429, Acc: 0.97\n",
      "Step [21300/50000], Loss: 0.2070, Acc: 0.95\n",
      "Step [21400/50000], Loss: 0.1979, Acc: 0.91\n",
      "Step [21500/50000], Loss: 0.1169, Acc: 0.97\n",
      "Step [21600/50000], Loss: 0.1905, Acc: 0.95\n",
      "Step [21700/50000], Loss: 0.1806, Acc: 0.93\n",
      "Step [21800/50000], Loss: 0.1374, Acc: 0.97\n",
      "Step [21900/50000], Loss: 0.2900, Acc: 0.95\n",
      "Step [22000/50000], Loss: 0.1292, Acc: 0.98\n",
      "Step [22100/50000], Loss: 0.2587, Acc: 0.94\n",
      "Step [22200/50000], Loss: 0.2288, Acc: 0.91\n",
      "Step [22300/50000], Loss: 0.1279, Acc: 0.97\n",
      "Step [22400/50000], Loss: 0.2234, Acc: 0.92\n",
      "Step [22500/50000], Loss: 0.1393, Acc: 0.96\n",
      "Step [22600/50000], Loss: 0.1507, Acc: 0.96\n",
      "Step [22700/50000], Loss: 0.2461, Acc: 0.91\n",
      "Step [22800/50000], Loss: 0.1940, Acc: 0.96\n",
      "Step [22900/50000], Loss: 0.1547, Acc: 0.96\n",
      "Step [23000/50000], Loss: 0.2519, Acc: 0.91\n",
      "Step [23100/50000], Loss: 0.3301, Acc: 0.92\n",
      "Step [23200/50000], Loss: 0.1653, Acc: 0.97\n",
      "Step [23300/50000], Loss: 0.1810, Acc: 0.98\n",
      "Step [23400/50000], Loss: 0.1304, Acc: 0.98\n",
      "Step [23500/50000], Loss: 0.1655, Acc: 0.93\n",
      "Step [23600/50000], Loss: 0.2336, Acc: 0.92\n",
      "Step [23700/50000], Loss: 0.2660, Acc: 0.93\n",
      "Step [23800/50000], Loss: 0.1481, Acc: 0.96\n",
      "Step [23900/50000], Loss: 0.1964, Acc: 0.93\n",
      "Step [24000/50000], Loss: 0.1760, Acc: 0.95\n",
      "Step [24100/50000], Loss: 0.1744, Acc: 0.93\n",
      "Step [24200/50000], Loss: 0.1881, Acc: 0.95\n",
      "Step [24300/50000], Loss: 0.2039, Acc: 0.93\n",
      "Step [24400/50000], Loss: 0.2657, Acc: 0.93\n",
      "Step [24500/50000], Loss: 0.1020, Acc: 0.99\n",
      "Step [24600/50000], Loss: 0.3251, Acc: 0.87\n",
      "Step [24700/50000], Loss: 0.1018, Acc: 0.99\n",
      "Step [24800/50000], Loss: 0.1650, Acc: 0.94\n",
      "Step [24900/50000], Loss: 0.1846, Acc: 0.95\n",
      "Step [25000/50000], Loss: 0.2937, Acc: 0.93\n",
      "Step [25100/50000], Loss: 0.2260, Acc: 0.92\n",
      "Step [25200/50000], Loss: 0.2783, Acc: 0.90\n",
      "Step [25300/50000], Loss: 0.1219, Acc: 0.98\n",
      "Step [25400/50000], Loss: 0.1513, Acc: 0.97\n",
      "Step [25500/50000], Loss: 0.2623, Acc: 0.91\n",
      "Step [25600/50000], Loss: 0.1827, Acc: 0.95\n",
      "Step [25700/50000], Loss: 0.2751, Acc: 0.90\n",
      "Step [25800/50000], Loss: 0.1960, Acc: 0.97\n",
      "Step [25900/50000], Loss: 0.2593, Acc: 0.91\n",
      "Step [26000/50000], Loss: 0.1391, Acc: 0.96\n",
      "Step [26100/50000], Loss: 0.1880, Acc: 0.94\n",
      "Step [26200/50000], Loss: 0.1964, Acc: 0.95\n",
      "Step [26300/50000], Loss: 0.1227, Acc: 0.98\n",
      "Step [26400/50000], Loss: 0.2066, Acc: 0.95\n",
      "Step [26500/50000], Loss: 0.2114, Acc: 0.90\n",
      "Step [26600/50000], Loss: 0.1620, Acc: 0.98\n",
      "Step [26700/50000], Loss: 0.1850, Acc: 0.96\n",
      "Step [26800/50000], Loss: 0.1484, Acc: 0.96\n",
      "Step [26900/50000], Loss: 0.1343, Acc: 0.96\n",
      "Step [27000/50000], Loss: 0.1327, Acc: 0.96\n",
      "Step [27100/50000], Loss: 0.2729, Acc: 0.92\n",
      "Step [27200/50000], Loss: 0.2658, Acc: 0.92\n",
      "Step [27300/50000], Loss: 0.1888, Acc: 0.92\n",
      "Step [27400/50000], Loss: 0.1439, Acc: 0.97\n",
      "Step [27500/50000], Loss: 0.1804, Acc: 0.94\n",
      "Step [27600/50000], Loss: 0.2399, Acc: 0.91\n",
      "Step [27700/50000], Loss: 0.1777, Acc: 0.96\n",
      "Step [27800/50000], Loss: 0.2218, Acc: 0.93\n",
      "Step [27900/50000], Loss: 0.1945, Acc: 0.94\n",
      "Step [28000/50000], Loss: 0.1808, Acc: 0.94\n",
      "Step [28100/50000], Loss: 0.2018, Acc: 0.93\n",
      "Step [28200/50000], Loss: 0.1344, Acc: 0.97\n",
      "Step [28300/50000], Loss: 0.1230, Acc: 0.98\n",
      "Step [28400/50000], Loss: 0.1259, Acc: 0.97\n",
      "Step [28500/50000], Loss: 0.2085, Acc: 0.92\n",
      "Step [28600/50000], Loss: 0.1192, Acc: 0.97\n",
      "Step [28700/50000], Loss: 0.2577, Acc: 0.92\n",
      "Step [28800/50000], Loss: 0.0615, Acc: 0.99\n",
      "Step [28900/50000], Loss: 0.1238, Acc: 0.96\n",
      "Step [29000/50000], Loss: 0.2400, Acc: 0.92\n",
      "Step [29100/50000], Loss: 0.1726, Acc: 0.93\n",
      "Step [29200/50000], Loss: 0.1055, Acc: 0.95\n",
      "Step [29300/50000], Loss: 0.1137, Acc: 0.97\n",
      "Step [29400/50000], Loss: 0.0916, Acc: 0.96\n",
      "Step [29500/50000], Loss: 0.2028, Acc: 0.93\n",
      "Step [29600/50000], Loss: 0.2088, Acc: 0.94\n",
      "Step [29700/50000], Loss: 0.2545, Acc: 0.93\n",
      "Step [29800/50000], Loss: 0.2189, Acc: 0.94\n",
      "Step [29900/50000], Loss: 0.2090, Acc: 0.94\n",
      "Step [30000/50000], Loss: 0.1242, Acc: 0.96\n",
      "Step [30100/50000], Loss: 0.1966, Acc: 0.92\n",
      "Step [30200/50000], Loss: 0.2150, Acc: 0.94\n",
      "Step [30300/50000], Loss: 0.3877, Acc: 0.94\n",
      "Step [30400/50000], Loss: 0.2912, Acc: 0.93\n",
      "Step [30500/50000], Loss: 0.2156, Acc: 0.96\n",
      "Step [30600/50000], Loss: 0.1516, Acc: 0.95\n",
      "Step [30700/50000], Loss: 0.0754, Acc: 0.98\n",
      "Step [30800/50000], Loss: 0.2383, Acc: 0.94\n",
      "Step [30900/50000], Loss: 0.1849, Acc: 0.95\n",
      "Step [31000/50000], Loss: 0.3023, Acc: 0.91\n",
      "Step [31100/50000], Loss: 0.1428, Acc: 0.97\n",
      "Step [31200/50000], Loss: 0.0986, Acc: 0.97\n",
      "Step [31300/50000], Loss: 0.1490, Acc: 0.97\n",
      "Step [31400/50000], Loss: 0.1936, Acc: 0.91\n",
      "Step [31500/50000], Loss: 0.1829, Acc: 0.95\n",
      "Step [31600/50000], Loss: 0.1124, Acc: 0.97\n",
      "Step [31700/50000], Loss: 0.2282, Acc: 0.95\n",
      "Step [31800/50000], Loss: 0.1423, Acc: 0.97\n",
      "Step [31900/50000], Loss: 0.1727, Acc: 0.96\n",
      "Step [32000/50000], Loss: 0.0890, Acc: 0.98\n",
      "Step [32100/50000], Loss: 0.1075, Acc: 0.97\n",
      "Step [32200/50000], Loss: 0.0930, Acc: 0.97\n",
      "Step [32300/50000], Loss: 0.1372, Acc: 0.97\n",
      "Step [32400/50000], Loss: 0.1434, Acc: 0.95\n",
      "Step [32500/50000], Loss: 0.0890, Acc: 0.98\n",
      "Step [32600/50000], Loss: 0.2099, Acc: 0.94\n",
      "Step [32700/50000], Loss: 0.2194, Acc: 0.93\n",
      "Step [32800/50000], Loss: 0.1948, Acc: 0.94\n",
      "Step [32900/50000], Loss: 0.1163, Acc: 0.97\n",
      "Step [33000/50000], Loss: 0.2470, Acc: 0.95\n",
      "Step [33100/50000], Loss: 0.2197, Acc: 0.94\n",
      "Step [33200/50000], Loss: 0.1364, Acc: 0.96\n",
      "Step [33300/50000], Loss: 0.0838, Acc: 0.99\n",
      "Step [33400/50000], Loss: 0.1384, Acc: 0.97\n",
      "Step [33500/50000], Loss: 0.3452, Acc: 0.92\n",
      "Step [33600/50000], Loss: 0.1869, Acc: 0.93\n",
      "Step [33700/50000], Loss: 0.2592, Acc: 0.94\n",
      "Step [33800/50000], Loss: 0.2322, Acc: 0.95\n",
      "Step [33900/50000], Loss: 0.1501, Acc: 0.96\n",
      "Step [34000/50000], Loss: 0.0920, Acc: 0.97\n",
      "Step [34100/50000], Loss: 0.2142, Acc: 0.93\n",
      "Step [34200/50000], Loss: 0.1596, Acc: 0.96\n",
      "Step [34300/50000], Loss: 0.2305, Acc: 0.94\n",
      "Step [34400/50000], Loss: 0.1505, Acc: 0.96\n",
      "Step [34500/50000], Loss: 0.1218, Acc: 0.97\n",
      "Step [34600/50000], Loss: 0.1621, Acc: 0.97\n",
      "Step [34700/50000], Loss: 0.1445, Acc: 0.96\n",
      "Step [34800/50000], Loss: 0.1805, Acc: 0.94\n",
      "Step [34900/50000], Loss: 0.1722, Acc: 0.95\n",
      "Step [35000/50000], Loss: 0.1460, Acc: 0.96\n",
      "Step [35100/50000], Loss: 0.2216, Acc: 0.94\n",
      "Step [35200/50000], Loss: 0.1407, Acc: 0.97\n",
      "Step [35300/50000], Loss: 0.1752, Acc: 0.94\n",
      "Step [35400/50000], Loss: 0.1642, Acc: 0.97\n",
      "Step [35500/50000], Loss: 0.2077, Acc: 0.96\n",
      "Step [35600/50000], Loss: 0.1990, Acc: 0.94\n",
      "Step [35700/50000], Loss: 0.1812, Acc: 0.95\n",
      "Step [35800/50000], Loss: 0.1095, Acc: 0.97\n",
      "Step [35900/50000], Loss: 0.2300, Acc: 0.94\n",
      "Step [36000/50000], Loss: 0.1596, Acc: 0.95\n",
      "Step [36100/50000], Loss: 0.1851, Acc: 0.94\n",
      "Step [36200/50000], Loss: 0.0671, Acc: 0.99\n",
      "Step [36300/50000], Loss: 0.2053, Acc: 0.94\n",
      "Step [36400/50000], Loss: 0.1474, Acc: 0.96\n",
      "Step [36500/50000], Loss: 0.2036, Acc: 0.94\n",
      "Step [36600/50000], Loss: 0.0958, Acc: 0.98\n",
      "Step [36700/50000], Loss: 0.3665, Acc: 0.94\n",
      "Step [36800/50000], Loss: 0.1027, Acc: 0.97\n",
      "Step [36900/50000], Loss: 0.1197, Acc: 0.96\n",
      "Step [37000/50000], Loss: 0.0910, Acc: 0.98\n",
      "Step [37100/50000], Loss: 0.0970, Acc: 0.97\n",
      "Step [37200/50000], Loss: 0.1900, Acc: 0.95\n",
      "Step [37300/50000], Loss: 0.2197, Acc: 0.92\n",
      "Step [37400/50000], Loss: 0.2111, Acc: 0.92\n",
      "Step [37500/50000], Loss: 0.1374, Acc: 0.96\n",
      "Step [37600/50000], Loss: 0.1355, Acc: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [37700/50000], Loss: 0.2042, Acc: 0.95\n",
      "Step [37800/50000], Loss: 0.2141, Acc: 0.94\n",
      "Step [37900/50000], Loss: 0.1211, Acc: 0.98\n",
      "Step [38000/50000], Loss: 0.1230, Acc: 0.97\n",
      "Step [38100/50000], Loss: 0.1292, Acc: 0.96\n",
      "Step [38200/50000], Loss: 0.2580, Acc: 0.96\n",
      "Step [38300/50000], Loss: 0.1367, Acc: 0.95\n",
      "Step [38400/50000], Loss: 0.1486, Acc: 0.94\n",
      "Step [38500/50000], Loss: 0.0844, Acc: 0.98\n",
      "Step [38600/50000], Loss: 0.1249, Acc: 0.98\n",
      "Step [38700/50000], Loss: 0.1288, Acc: 0.97\n",
      "Step [38800/50000], Loss: 0.0572, Acc: 0.99\n",
      "Step [38900/50000], Loss: 0.1843, Acc: 0.95\n",
      "Step [39000/50000], Loss: 0.2046, Acc: 0.95\n",
      "Step [39100/50000], Loss: 0.1196, Acc: 0.97\n",
      "Step [39200/50000], Loss: 0.1660, Acc: 0.97\n",
      "Step [39300/50000], Loss: 0.1210, Acc: 0.98\n",
      "Step [39400/50000], Loss: 0.1802, Acc: 0.95\n",
      "Step [39500/50000], Loss: 0.1546, Acc: 0.96\n",
      "Step [39600/50000], Loss: 0.0933, Acc: 0.97\n",
      "Step [39700/50000], Loss: 0.1251, Acc: 0.97\n",
      "Step [39800/50000], Loss: 0.2713, Acc: 0.91\n",
      "Step [39900/50000], Loss: 0.0927, Acc: 0.99\n",
      "Step [40000/50000], Loss: 0.1165, Acc: 0.98\n",
      "Step [40100/50000], Loss: 0.1785, Acc: 0.95\n",
      "Step [40200/50000], Loss: 0.0920, Acc: 0.98\n",
      "Step [40300/50000], Loss: 0.1289, Acc: 0.95\n",
      "Step [40400/50000], Loss: 0.1295, Acc: 0.96\n",
      "Step [40500/50000], Loss: 0.1702, Acc: 0.96\n",
      "Step [40600/50000], Loss: 0.2124, Acc: 0.94\n",
      "Step [40700/50000], Loss: 0.0643, Acc: 0.99\n",
      "Step [40800/50000], Loss: 0.2213, Acc: 0.95\n",
      "Step [40900/50000], Loss: 0.1106, Acc: 0.98\n",
      "Step [41000/50000], Loss: 0.1879, Acc: 0.92\n",
      "Step [41100/50000], Loss: 0.0703, Acc: 0.99\n",
      "Step [41200/50000], Loss: 0.2126, Acc: 0.97\n",
      "Step [41300/50000], Loss: 0.1850, Acc: 0.94\n",
      "Step [41400/50000], Loss: 0.1201, Acc: 0.96\n",
      "Step [41500/50000], Loss: 0.1932, Acc: 0.92\n",
      "Step [41600/50000], Loss: 0.1576, Acc: 0.95\n",
      "Step [41700/50000], Loss: 0.2101, Acc: 0.95\n",
      "Step [41800/50000], Loss: 0.1629, Acc: 0.97\n",
      "Step [41900/50000], Loss: 0.1514, Acc: 0.97\n",
      "Step [42000/50000], Loss: 0.1086, Acc: 0.98\n",
      "Step [42100/50000], Loss: 0.1334, Acc: 0.96\n",
      "Step [42200/50000], Loss: 0.1240, Acc: 0.96\n",
      "Step [42300/50000], Loss: 0.2096, Acc: 0.93\n",
      "Step [42400/50000], Loss: 0.1886, Acc: 0.97\n",
      "Step [42500/50000], Loss: 0.1281, Acc: 0.97\n",
      "Step [42600/50000], Loss: 0.0682, Acc: 0.97\n",
      "Step [42700/50000], Loss: 0.0921, Acc: 0.98\n",
      "Step [42800/50000], Loss: 0.3012, Acc: 0.95\n",
      "Step [42900/50000], Loss: 0.2027, Acc: 0.94\n",
      "Step [43000/50000], Loss: 0.3060, Acc: 0.92\n",
      "Step [43100/50000], Loss: 0.1228, Acc: 0.96\n",
      "Step [43200/50000], Loss: 0.2001, Acc: 0.93\n",
      "Step [43300/50000], Loss: 0.2164, Acc: 0.96\n",
      "Step [43400/50000], Loss: 0.0840, Acc: 0.98\n",
      "Step [43500/50000], Loss: 0.2066, Acc: 0.95\n",
      "Step [43600/50000], Loss: 0.1473, Acc: 0.96\n",
      "Step [43700/50000], Loss: 0.0947, Acc: 0.98\n",
      "Step [43800/50000], Loss: 0.1360, Acc: 0.96\n",
      "Step [43900/50000], Loss: 0.0513, Acc: 1.00\n",
      "Step [44000/50000], Loss: 0.1703, Acc: 0.94\n",
      "Step [44100/50000], Loss: 0.0702, Acc: 0.98\n",
      "Step [44200/50000], Loss: 0.0674, Acc: 0.97\n",
      "Step [44300/50000], Loss: 0.1990, Acc: 0.94\n",
      "Step [44400/50000], Loss: 0.1072, Acc: 0.94\n",
      "Step [44500/50000], Loss: 0.1648, Acc: 0.94\n",
      "Step [44600/50000], Loss: 0.1093, Acc: 0.98\n",
      "Step [44700/50000], Loss: 0.1308, Acc: 0.95\n",
      "Step [44800/50000], Loss: 0.1788, Acc: 0.94\n",
      "Step [44900/50000], Loss: 0.2877, Acc: 0.92\n",
      "Step [45000/50000], Loss: 0.1337, Acc: 0.97\n",
      "Step [45100/50000], Loss: 0.1962, Acc: 0.94\n",
      "Step [45200/50000], Loss: 0.0936, Acc: 0.96\n",
      "Step [45300/50000], Loss: 0.1044, Acc: 0.98\n",
      "Step [45400/50000], Loss: 0.1756, Acc: 0.96\n",
      "Step [45500/50000], Loss: 0.1506, Acc: 0.95\n",
      "Step [45600/50000], Loss: 0.1007, Acc: 0.98\n",
      "Step [45700/50000], Loss: 0.0777, Acc: 0.99\n",
      "Step [45800/50000], Loss: 0.0369, Acc: 1.00\n",
      "Step [45900/50000], Loss: 0.1962, Acc: 0.95\n",
      "Step [46000/50000], Loss: 0.2059, Acc: 0.95\n",
      "Step [46100/50000], Loss: 0.0883, Acc: 0.99\n",
      "Step [46200/50000], Loss: 0.0558, Acc: 0.97\n",
      "Step [46300/50000], Loss: 0.1072, Acc: 0.98\n",
      "Step [46400/50000], Loss: 0.1188, Acc: 0.97\n",
      "Step [46500/50000], Loss: 0.1303, Acc: 0.97\n",
      "Step [46600/50000], Loss: 0.1063, Acc: 0.97\n",
      "Step [46700/50000], Loss: 0.0848, Acc: 0.98\n",
      "Step [46800/50000], Loss: 0.1203, Acc: 0.95\n",
      "Step [46900/50000], Loss: 0.2705, Acc: 0.94\n",
      "Step [47000/50000], Loss: 0.0988, Acc: 0.99\n",
      "Step [47100/50000], Loss: 0.0965, Acc: 0.95\n",
      "Step [47200/50000], Loss: 0.0829, Acc: 0.98\n",
      "Step [47300/50000], Loss: 0.1617, Acc: 0.95\n",
      "Step [47400/50000], Loss: 0.0847, Acc: 0.99\n",
      "Step [47500/50000], Loss: 0.1085, Acc: 0.97\n",
      "Step [47600/50000], Loss: 0.1706, Acc: 0.95\n",
      "Step [47700/50000], Loss: 0.2133, Acc: 0.95\n",
      "Step [47800/50000], Loss: 0.1769, Acc: 0.96\n",
      "Step [47900/50000], Loss: 0.1349, Acc: 0.98\n",
      "Step [48000/50000], Loss: 0.2513, Acc: 0.94\n",
      "Step [48100/50000], Loss: 0.1186, Acc: 0.96\n",
      "Step [48200/50000], Loss: 0.1389, Acc: 0.95\n",
      "Step [48300/50000], Loss: 0.1445, Acc: 0.95\n",
      "Step [48400/50000], Loss: 0.0612, Acc: 0.98\n",
      "Step [48500/50000], Loss: 0.0711, Acc: 0.98\n",
      "Step [48600/50000], Loss: 0.1631, Acc: 0.95\n",
      "Step [48700/50000], Loss: 0.1388, Acc: 0.96\n",
      "Step [48800/50000], Loss: 0.1634, Acc: 0.95\n",
      "Step [48900/50000], Loss: 0.1064, Acc: 0.96\n",
      "Step [49000/50000], Loss: 0.1495, Acc: 0.98\n",
      "Step [49100/50000], Loss: 0.0890, Acc: 0.98\n",
      "Step [49200/50000], Loss: 0.0782, Acc: 0.98\n",
      "Step [49300/50000], Loss: 0.1032, Acc: 0.99\n",
      "Step [49400/50000], Loss: 0.0999, Acc: 0.98\n",
      "Step [49500/50000], Loss: 0.0858, Acc: 0.98\n",
      "Step [49600/50000], Loss: 0.2876, Acc: 0.93\n",
      "Step [49700/50000], Loss: 0.1045, Acc: 0.99\n",
      "Step [49800/50000], Loss: 0.1134, Acc: 0.97\n",
      "Step [49900/50000], Loss: 0.1275, Acc: 0.97\n",
      "Step [50000/50000], Loss: 0.1056, Acc: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for step in range(total_step):\n",
    "    \n",
    "    # Reset the data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # Fetch images and labels\n",
    "    images, labels = next(data_iter) #only when data_loader is converted to data_iter can \"next\" be used\n",
    "    images, labels = images.view(images.size(0), -1).to(device), labels.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute accuracy\n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    #torch.squeeze: Returns a tensor with all the dimensions of :attr:`input` of size `1` removed.\n",
    "    #.float() : equals to self.to(torch.float32), if without it:\n",
    "    # get RuntimeError: Can only calculate the mean of floating types. Got Byte instead.\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}' \n",
    "               .format(step+1, total_step, loss.item(), accuracy.item()))\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                        Tensorboard Logging                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # 1. Log scalar values (scalar summary)\n",
    "        info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "            # scalar_summary(self, tag, value, step): Log a scalar variable.\n",
    "            logger.scalar_summary(tag, value, step+1)\n",
    "\n",
    "        # 2. Log values and gradients of the parameters (histogram summary)\n",
    "        # torch.nn.modules.module.named_parameters(prefix='', recurse=True) method of __main__.NeuralNet instance\n",
    "        #  Returns an iterator over module parameters, yielding both the\n",
    "        #  name of the parameter as well as the parameter itself.\n",
    "        for tag, value in model.named_parameters():\n",
    "            # tag contains: fc1.weight, fc1.bias, fc2.weight, fc2.bias\n",
    "            tag = tag.replace('.', '/')\n",
    "            # histo_summary(tag, values, step, bins=1000) method of logger.Logger instance\n",
    "            #  Log a histogram of the tensor of values.\n",
    "            logger.histo_summary(tag, value.data.cpu().numpy(), step+1)\n",
    "            logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step+1)\n",
    "\n",
    "        # 3. Log training images (image summary)\n",
    "        info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
    "\n",
    "        for tag, images in info.items():\n",
    "            logger.image_summary(tag, images, step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir='./logs' --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
